---
layout: post
title: "Sentiment Analysis for women’s clothing E-commerce platform"
subtitle: "In this, we have to predict the number of positive and negative reviews based on sentiments by using different classification models. Using OSEMN framework."
background: '/img/posts/Sentiment-Analysis/vintage-shopping.jpg'
---

# -*- coding: utf-8 -*-
"""Day #24 - Sentiment Analysis for women’s clothing E-commerce platform.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14daGKbJn8oBZ-Afnerxgzswgai5EN6bt

### Name : Mohan S.
### Date : 4/8/21
### Topic : Day #24 Analyse Sentiments for TripAdvisor Hotels - Part 2.
**Sentiment Analysis for women’s clothing E-commerce platform.**

**Problem Statement:**

In this, we have to predict the number of positive and negative reviews based on sentiments by using different classification models.
Using OSEMN framework.
"""

# import libraries
import pandas as pd
import numpy as np
import seaborn as sns
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import spacy
import nltk

from nltk.sentiment.vader import SentimentIntensityAnalyzer
from sklearn.metrics.pairwise import cosine_similarity
nltk.download('vader_lexicon')
nltk.download('stopwords')

"""# **OBTAIN**"""

# read data & inspect it

df = pd.read_csv('/content/drive/MyDrive/Data Science Uncut Bootcamp/Womens Clothing E-Commerce Reviews.csv')
df.head()

df.shape

"""# **SCRUB**"""

df.isnull().sum()

#Checks the rating values in case there is a weird value
df["Rating"].value_counts()

#Checks for empty review strings
df.loc[df["Review Text"] == ""]

# Delete missing observations for following variables
for x in ["Division Name","Department Name","Class Name","Review Text"]:
    df = df[df[x].notnull()]

# Segregating and Encoding Positive, Neutral and Negative labels

pos = [5]
neg = [1, 2]
neu = [3, 4]

def sentiment(rating):
  if rating in pos:
    return 2
  elif rating in neg:
    return 0
  else:
    return 1  
df['Sentiment'] = df['Rating'].apply(sentiment)
df.head()

# plot chart to see the Positive/Neutral/Negative ratings.

sns.set(rc={'figure.figsize':(10,8)})
sns.countplot(data=df, x='Sentiment', color='palegreen')

"""# **EXPLORE (EDA)**"""

# Stopwords Removal.
from nltk.corpus import stopwords
stopwords_list = set(stopwords.words("english"))

#List of punctuation to remove
punctuations = """!()-![]{};:,+'"\,<>./?@#$%^&*_~Â""" 

def reviewParse(review):
    #Split the review into words  
    splitReview = review.split()
    #Takes the stubborn punctuation out
    parsedReview = " ".join([word.translate(str.maketrans('', '', punctuations)) + " " for word in splitReview]) 
    #Returns the parsed review
    return parsedReview #Returns the parsed review
  
def clean_review(review):
    clean_words = []
    splitReview = review.split()
    for w in splitReview:
        if w.isalpha() and w not in stopwords_list:
            clean_words.append(w.lower())
    clean_review = " ".join(clean_words)
    return clean_review

#Parse all the reviews for their punctuation and add it into a new column
df["Review Text"] = df["Review Text"].apply(reviewParse).apply(clean_review) 

#Take a peek at the dataset
df.head()

# Keyword used in different ratings
# Text mining - Visualization Type (wordCloud)

import matplotlib.pyplot as plt
from wordcloud import WordCloud

def wordcloud_generator(data, title=None):
    wordcloud = WordCloud(width = 800, height = 800,
                          background_color ='royalblue',
                          min_font_size = 10
                         ).generate(" ".join(data.values))
    
    # plot the WordCloud image                        
    plt.figure(figsize = (8, 8), facecolor = None) 
    plt.imshow(wordcloud, interpolation='bilinear') 
    plt.axis("off") 
    plt.tight_layout(pad = 0) 
    plt.title(title,fontsize=30)
    plt.show()

"""**Review for all Ratings**"""

# Reviews for all ratings!

wordcloud_generator(df['Review Text'], title="Most used words in reviews")

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer(stop_words='english')
feature = tfidf.fit_transform(df['Review Text'])

# Check Keyword
query = "fabric"
queryTFIDF = tfidf.transform([query])

# cosine similarity
cosims = cosine_similarity(queryTFIDF, feature).flatten()
results = cosims.argsort()[:-6:-1]

for r in results:
  print(df.iloc[r]['Review Text'])
  print("----")

#sentiment count
df['Sentiment'].value_counts()

"""About 10% out of whole reviews are Negative sentiments, the data looks imbalance.

# **MODELLING**
"""

docs = list(df['Review Text'])

# Creating TFIDF matrix
from sklearn.feature_extraction.text import TfidfVectorizer 
 
# settings that you use for count vectorizer will go here 
tfidf_vectorizer=TfidfVectorizer(use_idf=True)
 
# just send in all your docs here 
tfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(docs)

X = tfidf_vectorizer_vectors.toarray()
Y = df['Sentiment']
len(X[0])

# Divide the data into training and testing sets
from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV 
from sklearn.metrics import mean_absolute_error, accuracy_score, confusion_matrix, classification_report, roc_auc_score,roc_curve,auc
from sklearn.tree import DecisionTreeClassifier

SEED=123

X = tfidf_vectorizer_vectors.toarray()
Y = df['Sentiment']

X_train,X_test,y_train,y_test=train_test_split(X, Y, test_size=0.2, random_state=SEED, stratify=Y)

"""### 1.Decision Tree Classifier."""

dt = DecisionTreeClassifier(random_state=SEED)
dt.fit(X_train,y_train)
y_pred_test = dt.predict(X_test)
print("Training Accuracy score: "+str(round(accuracy_score(y_train,dt.predict(X_train)),4)))
print("Testing Accuracy score: "+str(round(accuracy_score(y_test,dt.predict(X_test)),4)))

print(classification_report(y_test, y_pred_test, target_names=['positive', 'neutral', 'negative']))

cm = confusion_matrix(y_test, y_pred_test)
#print('Confusion matrix\n', cm)
cm_matrix = pd.DataFrame(data=cm, columns=['Actual Negative', 'Actual Neutral', 'Actual Positive'], 
                        index=['Predict Negative', 'Predict Neutral', 'Predict Positive'])
sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')
plt.show()

"""### 2. Naive Bayes Classifier"""

from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
gnb.fit(X_train, y_train)
y_pred_train = gnb.predict(X_train)
y_pred_test = gnb.predict(X_test)
print("Training Accuracy score: "+str(round(accuracy_score(y_train,gnb.predict(X_train)),4)))
print("Testing Accuracy score: "+str(round(accuracy_score(y_test,gnb.predict(X_test)),4)))

print(classification_report(y_test, y_pred_test, target_names=['positive', 'neutral', 'negative']))

cm = confusion_matrix(y_test, y_pred_test)
#print('Confusion matrix\n', cm)
cm_matrix = pd.DataFrame(data=cm, columns=['Actual Negative', 'Actual Neutral', 'Actual Positive'], 
                        index=['Predict Negative', 'Predict Neutral', 'Predict Positive'])
sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')
plt.show()

"""### 3.Logistic Regression"""

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(random_state=SEED).fit(X_train, y_train)
y_pred_train = lr.predict(X_train)
y_pred_test = lr.predict(X_test)
print("Training Accuracy score: "+str(round(accuracy_score(y_train,lr.predict(X_train)),4)))
print("Testing Accuracy score: "+str(round(accuracy_score(y_test,lr.predict(X_test)),4)))

print(classification_report(y_test, y_pred_test, target_names=['positive', 'neutral', 'negative']))

cm = confusion_matrix(y_test, y_pred_test)
#print('Confusion matrix\n', cm)
cm_matrix = pd.DataFrame(data=cm, columns=['Actual Negative', 'Actual Neutral', 'Actual Positive'], 
                        index=['Predict Negative', 'Predict Neutral', 'Predict Positive'])
sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')
plt.show()

"""### 4. Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier()
clf.fit(X_train, y_train)
y_pred_train = clf.predict(X_train)
y_pred_test = clf.predict(X_test)
print("Training Accuracy score: "+str(round(accuracy_score(y_train,clf.predict(X_train)),4)))
print("Testing Accuracy score: "+str(round(accuracy_score(y_test,clf.predict(X_test)),4)))

print(classification_report(y_test, y_pred_test, target_names=['positive', 'neutral', 'negative']))

cm = confusion_matrix(y_test, y_pred_test)
#print('Confusion matrix\n', cm)
cm_matrix = pd.DataFrame(data=cm, columns=['Actual Negative', 'Actual Neutral', 'Actual Positive'], 
                        index=['Predict Negative', 'Predict Neutral', 'Predict Positive'])
sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')
plt.show()

"""## **My Findings:**

Using the TF-IDF technique, analysing "Keywords" in the reviews was not difficult. It's finds the keywords in the reviews pretty fine. However, in the overall reviews, we have very less negative reviews compared to positive reviews, it's looked like an im-balanced data.

We have reviews with 5 star but the compound score is negative. In contrast, we have a 1 star review with compound score is high. I suppose we cant analyze the review's sentiment by just looking at the computed normalizing value for the polarity scores (negative,neutral and positive).

Though it may seem easy, Sentiment Analysis is a tricky subject. A text may contain multiple sentiments all at once. Text sentiment analysis that is sensitive to both polarity (positive/negative) and intensity (strength) of emotion.

I guess the data need to be cleaned even further and the types of analysis to perform on the models. This will need to be used to measure the attitude, sentiments, evaluations, and emotions of a writer or reviewer.
"""